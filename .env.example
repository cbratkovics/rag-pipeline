# Application Settings
APP_NAME=rag-pipeline
APP_ENV=development
DEBUG=true
LOG_LEVEL=INFO

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
BASE_URL=http://localhost:8000
API_KEY_HEADER=X-API-Key
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]

# Database Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=rag_pipeline
POSTGRES_USER=rag_user
POSTGRES_PASSWORD=secure_password_here
DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_URL=redis://${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}

# Vector Store Configuration
VECTOR_STORE_TYPE=chromadb  # ChromaDB is the primary vector store
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_API_KEY=
QDRANT_COLLECTION=rag_documents
CHROMADB_HOST=localhost
CHROMADB_PORT=8000
CHROMADB_COLLECTION=rag_documents
CHROMA_PERSIST_DIR=.chroma  # Use /var/data/chroma for Render deployment
PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python  # Required for ChromaDB

# Embedding Model Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
EMBEDDING_BATCH_SIZE=32

# LLM Configuration - OpenAI is the only supported provider
OPENAI_API_KEY=sk-...  # REQUIRED: Add your OpenAI API key here
OPENAI_MODEL=gpt-3.5-turbo  # OpenAI model to use for generation

# Reranking Configuration
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANKER_TOP_K=10

# Search Configuration
HYBRID_SEARCH_ALPHA=0.5  # Balance between dense and sparse search
BM25_K1=1.2
BM25_B=0.75
SEARCH_TOP_K=20
FINAL_TOP_K=5
TOP_K_VECTOR=8
TOP_K_BM25=8
RRF_K=60
HYBRID_WEIGHT_VECTOR=0.5
HYBRID_WEIGHT_BM25=0.5

# RAG Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MAX_CONTEXT_LENGTH=2048
TEMPERATURE=0.7
MAX_TOKENS=512

# A/B Testing Configuration
AB_TEST_ENABLED=true
AB_TEST_VARIANTS=["baseline", "reranked", "hybrid", "finetuned"]
AB_TEST_DEFAULT_VARIANT=baseline
AB_TEST_TRAFFIC_SPLIT=[0.25, 0.25, 0.25, 0.25]
AB_TEST_MIN_SAMPLES=100
AB_TEST_CONFIDENCE_LEVEL=0.95

# RAGAS Evaluation Configuration
RAGAS_ENABLED=true
RAGAS_METRICS=["context_relevancy", "answer_faithfulness", "answer_relevancy", "context_recall"]
RAGAS_THRESHOLD_CONTEXT_RELEVANCY=0.8
RAGAS_THRESHOLD_ANSWER_FAITHFULNESS=0.8
RAGAS_THRESHOLD_ANSWER_RELEVANCY=0.8
RAGAS_THRESHOLD_CONTEXT_RECALL=0.7

# Monitoring Configuration
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090
PROMETHEUS_MULTIPROC_DIR=/tmp/prometheus_multiproc
GRAFANA_ENABLED=true
GRAFANA_PORT=3000
OPENTELEMETRY_ENABLED=true
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=rag-pipeline

# MLflow Configuration
MLFLOW_TRACKING_URI=file:./mlruns
MLFLOW_EXPERIMENT_NAME=rag-eval
MLFLOW_ARTIFACT_LOCATION=./mlruns

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_REQUESTS_PER_HOUR=1000
RATE_LIMIT_REQUESTS_PER_DAY=10000

# Security
JWT_SECRET_KEY=your-secret-key-here-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24
BCRYPT_ROUNDS=12

# Data Sources
ARXIV_ENABLED=true
WIKIPEDIA_ENABLED=true
COMMON_CRAWL_ENABLED=false
SEC_EDGAR_ENABLED=false
PUBMED_ENABLED=false

# Feedback Configuration
FEEDBACK_ENABLED=true
FEEDBACK_MIN_SCORE=1
FEEDBACK_MAX_SCORE=5
FEEDBACK_RETRAINING_THRESHOLD=100
FEEDBACK_NEGATIVE_THRESHOLD=0.3

# Performance Settings
MAX_WORKERS=4
CONNECTION_POOL_SIZE=20
REQUEST_TIMEOUT_SECONDS=30
BACKGROUND_TASK_TIMEOUT_SECONDS=300

# Cache Settings
CACHE_TTL_SECONDS=3600
CACHE_MAX_SIZE=1000

# Feature Flags
FEATURE_QUERY_EXPANSION=true
FEATURE_METADATA_FILTERING=true
FEATURE_DYNAMIC_CHUNKING=true
FEATURE_ONLINE_LEARNING=false
FEATURE_COST_TRACKING=true

# Cost Tracking
COST_PER_EMBEDDING_REQUEST=0.0001
COST_PER_LLM_TOKEN=0.000002
COST_PER_RERANK_REQUEST=0.00005
COST_PER_VECTOR_SEARCH=0.00001

# Deployment
DEPLOYMENT_ENVIRONMENT=development
DEPLOYMENT_REGION=us-west-2
DEPLOYMENT_VERSION=0.1.0